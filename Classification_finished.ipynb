{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(pred, y):\n",
    "    return sum(pred != y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И класс терминального узла (листа)\n",
    "\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels, sample_weights):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.sample_weights = sample_weights\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for num, label in enumerate(self.labels):\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += self.sample_weights[num]\n",
    "            \n",
    "        # найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ИЗМЕНЕНИЯ: дерево организуем тоже классом\n",
    "# Класс дерева\n",
    "\n",
    "class Tree:\n",
    "    \n",
    "    # ИЗМЕНЕНИЯ: здесь указаны параметры для останова\n",
    "    def __init__(self,\n",
    "                 max_tree_depth_stop=np.inf,\n",
    "                 max_leaf_num_stop=np.inf,\n",
    "                 min_leaf_object_stop=1):\n",
    "        self.max_depth = max_tree_depth_stop\n",
    "        self.nodes = []\n",
    "        self.leaves = []\n",
    "        self.depth = 0\n",
    "        self.max_leaves = max_leaf_num_stop\n",
    "        self.min_objects = min_leaf_object_stop\n",
    "        self.tree = None\n",
    "        \n",
    "    # Расчет критерия Джини\n",
    "    def gini(self,\n",
    "             labels,\n",
    "             sample_weights):\n",
    "        #  подсчет количества объектов разных классов\n",
    "        classes = {}\n",
    "        \n",
    "        #################################\n",
    "        for num, label in enumerate(labels):\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += sample_weights[num]\n",
    "        \n",
    "\n",
    "        #  расчет критерия\n",
    "        impurity = 1\n",
    "        for label in classes:\n",
    "                                ###################\n",
    "            p = classes[label] / sum(sample_weights)\n",
    "            impurity -= p ** 2\n",
    "\n",
    "        return impurity\n",
    "     \n",
    "    # Расчет прироста\n",
    "    def gain(self,\n",
    "             left_labels,\n",
    "             right_labels,\n",
    "             root_gini,\n",
    "             true_sw,\n",
    "             false_sw):\n",
    "\n",
    "        # доля выборки, ушедшая в левое поддерево\n",
    "        p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "        \n",
    "                                                     #######                                     ##########\n",
    "        return root_gini - p * self.gini(left_labels,true_sw) - (1 - p) * self.gini(right_labels,false_sw)\n",
    "    \n",
    "    # Разбиение датасета в узле\n",
    "    def split(self,\n",
    "              data,\n",
    "              labels,\n",
    "              column_index,\n",
    "                  ###################\n",
    "              t, sample_weights):\n",
    "                ##################\n",
    "\n",
    "        left = np.where(data[:, column_index] <= t)\n",
    "        right = np.where(data[:, column_index] > t)\n",
    "\n",
    "        true_data = data[left]\n",
    "        false_data = data[right]\n",
    "\n",
    "        true_labels = labels[left]\n",
    "        false_labels = labels[right]\n",
    "        ###############################\n",
    "        true_sw = sample_weights[left]\n",
    "        false_sw = sample_weights[right]\n",
    "        ###############################\n",
    "        return true_data, false_data, true_labels, false_labels, true_sw, false_sw \n",
    "    \n",
    "    # Нахождение наилучшего разбиения\n",
    "    def find_best_split(self,\n",
    "                        data,\n",
    "                        labels,\n",
    "                        ################\n",
    "                        sample_weights):\n",
    "                        ################\n",
    "        \n",
    "        #  обозначим минимальное количество объектов в узле\n",
    "        min_samples_leaf =  self.min_objects\n",
    "\n",
    "                                      ##############\n",
    "        root_gini = self.gini(labels, sample_weights)\n",
    "                                      ##############\n",
    "        \n",
    "        best_gain = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "\n",
    "        n_features = data.shape[1]\n",
    "\n",
    "        for index in range(n_features):\n",
    "            # будем проверять только уникальные значения признака, исключая повторения\n",
    "            t_values = np.unique(data[:, index])\n",
    "\n",
    "            for t in t_values:\n",
    "\n",
    "                                                                  ######### #########                            ##############\n",
    "                true_data, false_data, true_labels, false_labels, true_sw, false_sw = self.split(data, labels, index, t, sample_weights)\n",
    "                                                                  #########  #########                          ##############\n",
    " \n",
    "                    \n",
    "                #  пропускаем разбиения, в которых в узле остается менее min_leaf_object_stop\n",
    "                if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                    continue\n",
    "                    \n",
    "                                                                               ############## gini split gain\n",
    "                current_gain = self.gain(true_labels, false_labels, root_gini, true_sw, false_sw)\n",
    "\n",
    "                #  выбираем порог, на котором получается максимальный прирост качества\n",
    "                if current_gain > best_gain:\n",
    "                    best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "        return best_gain, best_t, best_index\n",
    "    \n",
    "    # Построение дерева с помощью рекурсивной функции\n",
    "    def build_tree(self,\n",
    "                   data,\n",
    "                   labels,\n",
    "                   ################################\n",
    "                   sample_weights\n",
    "                   ################################\n",
    "                   ):\n",
    "                                                            ###############\n",
    "        gain, t, index = self.find_best_split(data, labels, sample_weights)\n",
    "                                                            ###############\n",
    "        \n",
    " \n",
    "        #  Базовый случай 2 - прекращаем рекурсию, когда достигли максимальной глубины дерева\n",
    "        if self.depth > self.max_depth:\n",
    "            self.leaves.append(Leaf(data, labels, sample_weights))\n",
    "            return Leaf(data, labels, sample_weights)\n",
    "        \n",
    "        #  Базовый случай 3 - прекращаем рекурсию, когда достигли максимального количества листьев\n",
    "        if len(self.leaves) >= self.max_leaves - 1 or self.depth >= self.max_leaves - 1:\n",
    "            self.leaves.append(Leaf(data, labels, sample_weights))\n",
    "            return Leaf(data, labels, sample_weights)\n",
    "        \n",
    "        #  Базовый случай 4 - прекращаем рекурсию, когда достигли минимального количества объектов в листе\n",
    "        if len(data) <= self.min_objects:\n",
    "            self.leaves.append(Leaf(data, labels, sample_weights))\n",
    "            return Leaf(data, labels, sample_weights)\n",
    "        \n",
    "         #  Базовый случай 1 - прекращаем рекурсию, когда нет прироста в качества\n",
    "        if gain == 0:\n",
    "            self.leaves.append(Leaf(data, labels, sample_weights))\n",
    "            return Leaf(data, labels, sample_weights)\n",
    "\n",
    "        self.depth += 1\n",
    "        \n",
    "                                                          ######### #########                            ##############\n",
    "        true_data, false_data, true_labels, false_labels, true_sw, false_sw = self.split(data, labels, index, t, sample_weights)\n",
    "                                                          #########  #########                          ##############\n",
    "        \n",
    "        \n",
    "        # Рекурсивно строим два поддерева\n",
    "        true_branch = self.build_tree(true_data, true_labels , true_sw)\n",
    "        false_branch = self.build_tree(false_data, false_labels, false_sw)\n",
    "\n",
    "        # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "        self.nodes.append(Node(index, t, true_branch, false_branch))\n",
    "        return Node(index, t, true_branch, false_branch)\n",
    "    \n",
    "    def classify_object(self,\n",
    "                        obj,\n",
    "                        node):\n",
    "\n",
    "        #  Останавливаем рекурсию, если достигли листа\n",
    "        if isinstance(node, Leaf):\n",
    "            answer = node.prediction\n",
    "            return answer\n",
    "\n",
    "        if obj[node.index] <= node.t:\n",
    "            return self.classify_object(obj, node.true_branch)\n",
    "        else:\n",
    "            return self.classify_object(obj, node.false_branch)\n",
    "                                \n",
    "    def fit(self, data, labels, sample_weights=None):\n",
    "        ################\n",
    "        if sample_weights is None:\n",
    "            sample_weights=np.ones(len(labels))\n",
    "                                   \n",
    "        ###############\n",
    "        labels = labels.flatten()\n",
    "        #########\n",
    "        self.tree = self.build_tree(data, labels, sample_weights)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "    \n",
    "        classes = []\n",
    "        for obj in data:\n",
    "            prediction = self.classify_object(obj, self.tree)\n",
    "            classes.append(prediction)\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost(X, y, N, depth):\n",
    "\n",
    "    # Размер выборки\n",
    "    n_objects = len(X)\n",
    "\n",
    "    # Запишем количество классов в переменную\n",
    "    n_classes = len(np.unique((y)))\n",
    "\n",
    "    # Начальные веса объектов\n",
    "    w = np.ones(n_objects) / n_objects\n",
    "    #w[[i for i, n in enumerate(y) if n == 1]]=1\n",
    "\n",
    "    # Деревья с весами будем записывать в список\n",
    "    models = []\n",
    "\n",
    "    for n in range(N):\n",
    "        # Зададим дерево и обучим его\n",
    "        #clf = DecisionTreeClassifier(max_depth=depth)\n",
    "        clf = Tree(max_tree_depth_stop=depth, max_leaf_num_stop=np.inf, min_leaf_object_stop=1)\n",
    "        clf.fit(X, y, sample_weights=w)\n",
    "\n",
    "        predictions = clf.predict(X)\n",
    "        error = get_error(predictions, y)\n",
    "        \n",
    "        # отбросим дерево, если его ошибка больше 0.5\n",
    "        # Запишем условие в общем виде (применимо к небинарным классификаторам)\n",
    "        if error >= 1 - 1/n_classes: \n",
    "            continue\n",
    "\n",
    "        # Обработаем граничные значения ошибок\n",
    "        if error == 0:\n",
    "            error += 1e-10\n",
    "        elif error == 1:\n",
    "            error -= 1e-10\n",
    "        # Вычислим вес для дерева\n",
    "        alpha = 0.5 * np.log((1 - error) / error)\n",
    "\n",
    "\n",
    "        # Найдем индексы неправильно классифицированных элементов\n",
    "        wrong_mask = predictions != y\n",
    "\n",
    "        # Увеличим веса для неправильно классифицированных элементов\n",
    "        w[wrong_mask] *= np.exp(alpha)\n",
    "        # Уменьшаем веса для правильно классифицированных элементов\n",
    "        w[~wrong_mask] *= np.exp(-alpha)\n",
    "\n",
    "        # Нормализуем веса\n",
    "        w /= w.sum()\n",
    "\n",
    "        # Добавим дерево с весом в список\n",
    "        models.append((alpha, clf))\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, models):\n",
    "    \n",
    "    n_classes = 2\n",
    "    n_objects = len(X)\n",
    "    \n",
    "    # вначале обозначим предсказание нулевым массивом\n",
    "    y_pred = np.ones((n_objects, n_classes))\n",
    "    \n",
    "    for alpha, clf in models:\n",
    "        prediction = clf.predict(X)\n",
    "        # Для каждого предсказания будем прибавлять alpha к\n",
    "        # элементу с индексом предсказанного класса\n",
    "        y_pred[range(n_objects), prediction] += alpha\n",
    "    \n",
    "    # выберем индексы с максимальными суммарными весами -\n",
    "    # получим предсказанные алгоритмом классы\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[:, X_train.columns != 'Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train.loc[:, X_train.columns != 'choose'], X_train[['choose']], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'years_of_experience', 'lesson_price', 'qualification',\n",
       "       'physics', 'chemistry', 'biology', 'english', 'geography', 'history',\n",
       "       'mean_exam_points'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extended dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train2.loc[:, X_train2.columns != 'Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'years_of_experience', 'lesson_price', 'qualification',\n",
       "       'physics', 'chemistry', 'biology', 'english', 'geography', 'history',\n",
       "       'mean_exam_points', 'choose'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2['price_per_point']=X_train2['lesson_price']/X_train2['mean_exam_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2['price_per_qualification']=X_train2['lesson_price']/X_train2['qualification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2['exp_per_price']=X_train2['years_of_experience']/X_train2['lesson_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train2.loc[:, X_train2.columns != 'choose'], X_train2[['choose']], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'years_of_experience', 'lesson_price', 'qualification',\n",
       "       'physics', 'chemistry', 'biology', 'english', 'geography', 'history',\n",
       "       'mean_exam_points', 'price_per_point', 'price_per_qualification',\n",
       "       'exp_per_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros2, y_ros2 = ros.fit_resample(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus2, y_rus2 = rus.fit_resample(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros, y_ros = X_ros.to_numpy(), y_ros.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus, y_rus = X_rus.to_numpy(), y_rus.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros2, y_ros2 = X_ros2.to_numpy(), y_ros2.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus2, y_rus2 = X_rus2.to_numpy(), y_rus2.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = X_test.to_numpy(), y_test.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testtesttest\n",
    "results2 = []\n",
    "for N in range(10,25):\n",
    "    for depth in range(3,20):\n",
    "        models = adaboost(X_rus, y_rus, N, depth)\n",
    "        results2.append((N,depth,roc_auc_score(y_rus, predict(X_rus, models)),roc_auc_score(y_test, predict(X_test, models))))\n",
    "        print((N,depth,roc_auc_score(y_rus, predict(X_rus, models)),roc_auc_score(y_test, predict(X_test, models))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = sorted(results2, key = lambda x: x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19, 14, 0.7742927429274292, 0.7629341001618678),\n",
       " (16, 11, 0.7730627306273062, 0.7633142443714132),\n",
       " (19, 11, 0.7816728167281674, 0.7657851817334576),\n",
       " (20, 11, 0.7816728167281674, 0.7657851817334576),\n",
       " (18, 11, 0.7718327183271831, 0.766361529405994)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (11, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (12, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (13, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (14, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (15, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (16, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (17, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (18, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (19, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (20, 6, 0.6838868388683886, 0.6716044538186099),\n",
       " (10, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (10, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (11, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (11, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (12, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (12, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (13, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (13, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (14, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (14, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (15, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (15, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (16, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (16, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (17, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (17, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (18, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (18, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (19, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (19, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (20, 7, 0.6857318573185732, 0.6724107274243392),\n",
       " (20, 8, 0.6857318573185732, 0.6724107274243392),\n",
       " (10, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (10, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (10, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (11, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (11, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (11, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (12, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (12, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (12, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (13, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (13, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (13, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (14, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (14, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (14, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (15, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (15, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (15, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (16, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (16, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (16, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (17, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (17, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (17, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (18, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (18, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (18, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (19, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (19, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (19, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (20, 3, 0.6832718327183271, 0.6730667827537156),\n",
       " (20, 4, 0.6832718327183271, 0.6730667827537156),\n",
       " (20, 5, 0.6832718327183271, 0.6730667827537156),\n",
       " (19, 16, 0.7091020910209103, 0.6850198656006278),\n",
       " (12, 17, 0.7103321033210331, 0.6870554765291608),\n",
       " (14, 17, 0.7103321033210331, 0.6870554765291608),\n",
       " (17, 17, 0.7103321033210331, 0.6870554765291608),\n",
       " (10, 17, 0.7103321033210331, 0.6872823367832442),\n",
       " (16, 17, 0.7103321033210331, 0.6872823367832442),\n",
       " (10, 15, 0.7084870848708487, 0.687408029626723),\n",
       " (12, 16, 0.7091020910209103, 0.6892750282042479),\n",
       " (14, 16, 0.7091020910209103, 0.6892750282042479),\n",
       " (16, 16, 0.7091020910209103, 0.6892750282042479),\n",
       " (12, 18, 0.711562115621156, 0.6892995536371217),\n",
       " (14, 18, 0.711562115621156, 0.6892995536371217),\n",
       " (16, 18, 0.711562115621156, 0.6892995536371217),\n",
       " (10, 16, 0.7091020910209103, 0.6895018884583313),\n",
       " (10, 18, 0.711562115621156, 0.6895264138912052),\n",
       " (17, 19, 0.7121771217712177, 0.6899801343993721),\n",
       " (19, 19, 0.7121771217712177, 0.6899801343993721),\n",
       " (10, 19, 0.7121771217712177, 0.6902069946534558),\n",
       " (12, 19, 0.7121771217712177, 0.6902069946534558),\n",
       " (14, 19, 0.7121771217712177, 0.6906607151616226),\n",
       " (16, 19, 0.7121771217712177, 0.6906607151616226),\n",
       " (13, 17, 0.7183271832718328, 0.6932788051209104),\n",
       " (15, 17, 0.7183271832718328, 0.6932788051209104),\n",
       " (11, 17, 0.7183271832718328, 0.6935056653749938),\n",
       " (18, 17, 0.7183271832718328, 0.6935056653749938),\n",
       " (11, 15, 0.7164821648216482, 0.6936313582184727),\n",
       " (13, 15, 0.7164821648216482, 0.6936313582184727),\n",
       " (12, 9, 0.7146371463714637, 0.6936834747633296),\n",
       " (13, 9, 0.7146371463714637, 0.6936834747633296),\n",
       " (16, 9, 0.7146371463714637, 0.6936834747633296),\n",
       " (17, 9, 0.7146371463714637, 0.6936834747633296),\n",
       " (18, 9, 0.7146371463714637, 0.6936834747633296),\n",
       " (19, 9, 0.7146371463714637, 0.6936834747633296),\n",
       " (20, 9, 0.7146371463714637, 0.6936834747633296),\n",
       " (13, 18, 0.7195571955719556, 0.6938336930396821),\n",
       " (12, 15, 0.7164821648216482, 0.6938858095845392),\n",
       " (14, 9, 0.7146371463714637, 0.69436405552558),\n",
       " (15, 9, 0.7146371463714637, 0.69436405552558),\n",
       " (10, 9, 0.7146371463714637, 0.6950446362878304),\n",
       " (11, 9, 0.7146371463714637, 0.6950446362878304),\n",
       " (13, 16, 0.7170971709717098, 0.6954983567959974),\n",
       " (15, 16, 0.7170971709717098, 0.6954983567959974),\n",
       " (17, 16, 0.7170971709717098, 0.6954983567959974),\n",
       " (18, 16, 0.7170971709717098, 0.6954983567959974),\n",
       " (15, 18, 0.7195571955719556, 0.6955228822288714),\n",
       " (17, 18, 0.7195571955719556, 0.6955228822288714),\n",
       " (18, 18, 0.7195571955719556, 0.6955228822288714),\n",
       " (10, 13, 0.7164821648216483, 0.695700691617207),\n",
       " (11, 16, 0.7170971709717098, 0.6957252170500808),\n",
       " (11, 18, 0.7195571955719556, 0.6957497424829547),\n",
       " (18, 19, 0.7201722017220171, 0.6962034629911219),\n",
       " (11, 19, 0.7201722017220171, 0.6964303232452053),\n",
       " (13, 19, 0.7201722017220171, 0.6964303232452053),\n",
       " (15, 19, 0.7201722017220171, 0.6968840437533723),\n",
       " (14, 15, 0.7183271832718328, 0.6969545543728846),\n",
       " (10, 14, 0.7164821648216482, 0.6980704615686466),\n",
       " (19, 18, 0.7170971709717097, 0.7007284053563545),\n",
       " (11, 10, 0.7244772447724477, 0.709465590817678),\n",
       " (12, 14, 0.7306273062730628, 0.7100695296021975),\n",
       " (10, 10, 0.7275522755227553, 0.7112314219845979),\n",
       " (13, 10, 0.7275522755227553, 0.7112314219845979),\n",
       " (14, 10, 0.7275522755227553, 0.7112314219845979),\n",
       " (18, 10, 0.7275522755227553, 0.7112314219845979),\n",
       " (19, 10, 0.7275522755227553, 0.7112314219845979),\n",
       " (17, 10, 0.7250922509225093, 0.711308063962329),\n",
       " (11, 12, 0.7300123001230013, 0.7145331583852456),\n",
       " (13, 13, 0.7306273062730626, 0.7152995781625546),\n",
       " (12, 10, 0.7367773677736779, 0.7170010300681807),\n",
       " (15, 10, 0.7392373923739236, 0.7236075685485848),\n",
       " (16, 10, 0.7392373923739236, 0.7236075685485848),\n",
       " (20, 10, 0.7392373923739236, 0.7236075685485848),\n",
       " (19, 17, 0.7416974169741698, 0.7250392406925982),\n",
       " (15, 13, 0.7515375153751538, 0.7269890126060724),\n",
       " (11, 13, 0.7361623616236164, 0.7275101780546427),\n",
       " (12, 13, 0.7361623616236164, 0.7275101780546427),\n",
       " (11, 14, 0.7398523985239852, 0.7277891548535831),\n",
       " (10, 12, 0.7337023370233702, 0.7287456467356649),\n",
       " (15, 15, 0.7552275522755229, 0.73807757394418),\n",
       " (10, 11, 0.7521525215252153, 0.7382523176534065),\n",
       " (17, 13, 0.7595325953259533, 0.7386508559376073),\n",
       " (12, 11, 0.7546125461254612, 0.7398127483200077),\n",
       " (13, 14, 0.7564575645756457, 0.7417073380095159),\n",
       " (12, 12, 0.7546125461254612, 0.7419127385098347),\n",
       " (18, 13, 0.7595325953259533, 0.7421120076519351),\n",
       " (16, 15, 0.7589175891758917, 0.7431727326237308),\n",
       " (15, 11, 0.7706027060270603, 0.7443070338941483),\n",
       " (17, 15, 0.7613776137761378, 0.7445338941482318),\n",
       " (14, 13, 0.7607626076260763, 0.7472776769509982),\n",
       " (16, 13, 0.7613776137761378, 0.7472776769509982),\n",
       " (14, 12, 0.7533825338253384, 0.7477651199293668),\n",
       " (15, 12, 0.7638376383763837, 0.7481605925344581),\n",
       " (13, 11, 0.7589175891758918, 0.7484640947662726),\n",
       " (19, 13, 0.7619926199261993, 0.7485407367440035),\n",
       " (11, 11, 0.7564575645756457, 0.7487921224309608),\n",
       " (18, 15, 0.7669126691266913, 0.7488473046549271),\n",
       " (19, 15, 0.7662976629766298, 0.7488473046549271),\n",
       " (16, 14, 0.7656826568265682, 0.7507296316279982),\n",
       " (13, 12, 0.7619926199261994, 0.7512630597930054),\n",
       " (14, 14, 0.7669126691266913, 0.7517167803011723),\n",
       " (14, 11, 0.7650676506765068, 0.7521183842644822),\n",
       " (15, 14, 0.7638376383763839, 0.7521705008093391),\n",
       " (16, 12, 0.7644526445264452, 0.7551748663363909),\n",
       " (17, 12, 0.7638376383763837, 0.7556285868445578),\n",
       " (18, 12, 0.7638376383763837, 0.7556285868445578),\n",
       " (19, 12, 0.7638376383763837, 0.7556285868445578),\n",
       " (20, 12, 0.7638376383763837, 0.7556285868445578),\n",
       " (17, 11, 0.7779827798277983, 0.76031601020258),\n",
       " (17, 14, 0.7742927429274292, 0.7629341001618678),\n",
       " (18, 14, 0.7742927429274292, 0.7629341001618678),\n",
       " (19, 14, 0.7742927429274292, 0.7629341001618678),\n",
       " (16, 11, 0.7730627306273062, 0.7633142443714132),\n",
       " (19, 11, 0.7816728167281674, 0.7657851817334576),\n",
       " (20, 11, 0.7816728167281674, 0.7657851817334576),\n",
       " (18, 11, 0.7718327183271831, 0.766361529405994)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение итоговой модели на андерсемплиновых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = X[['choose']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[:, X.columns != 'Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[:, X.columns != 'choose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X.to_numpy(), y.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus, y_rus = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7542831379621281"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = adaboost(X_rus, y_rus, 40, 11)\n",
    "\n",
    "roc_auc_score(y_rus, predict(X_rus, models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>lesson_price</th>\n",
       "      <th>qualification</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "      <th>biology</th>\n",
       "      <th>english</th>\n",
       "      <th>geography</th>\n",
       "      <th>history</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19995</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19996</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19997</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19998</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19999</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id   age  years_of_experience  lesson_price  qualification  physics  \\\n",
       "0     10000  32.0                  2.0        2700.0            3.0      0.0   \n",
       "1     10001  35.0                  6.0        1800.0            2.0      1.0   \n",
       "2     10002  44.0                  2.0        1200.0            1.0      0.0   \n",
       "3     10003  44.0                  4.0        2950.0            3.0      1.0   \n",
       "4     10004  38.0                  3.0        1400.0            2.0      1.0   \n",
       "...     ...   ...                  ...           ...            ...      ...   \n",
       "9995  19995  44.0                  3.0        1850.0            2.0      1.0   \n",
       "9996  19996  45.0                  3.0        2450.0            2.0      1.0   \n",
       "9997  19997  44.0                  2.0        1250.0            1.0      1.0   \n",
       "9998  19998  51.0                  5.0        1000.0            2.0      1.0   \n",
       "9999  19999  43.0                  0.0        1500.0            1.0      1.0   \n",
       "\n",
       "      chemistry  biology  english  geography  history  mean_exam_points  \n",
       "0           0.0      0.0      0.0        0.0      0.0              90.0  \n",
       "1           1.0      0.0      0.0        0.0      0.0              71.0  \n",
       "2           0.0      0.0      0.0        0.0      0.0              45.0  \n",
       "3           0.0      0.0      0.0        0.0      0.0              92.0  \n",
       "4           0.0      0.0      0.0        0.0      0.0              58.0  \n",
       "...         ...      ...      ...        ...      ...               ...  \n",
       "9995        1.0      0.0      0.0        0.0      0.0              68.0  \n",
       "9996        1.0      0.0      1.0        0.0      0.0              72.0  \n",
       "9997        1.0      0.0      0.0        0.0      0.0              63.0  \n",
       "9998        0.0      1.0      0.0        0.0      0.0              64.0  \n",
       "9999        1.0      1.0      0.0        0.0      0.0              41.0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = X_new[['Id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_new.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>lesson_price</th>\n",
       "      <th>qualification</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "      <th>biology</th>\n",
       "      <th>english</th>\n",
       "      <th>geography</th>\n",
       "      <th>history</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  years_of_experience  lesson_price  qualification  physics  \\\n",
       "0     32.0                  2.0        2700.0            3.0      0.0   \n",
       "1     35.0                  6.0        1800.0            2.0      1.0   \n",
       "2     44.0                  2.0        1200.0            1.0      0.0   \n",
       "3     44.0                  4.0        2950.0            3.0      1.0   \n",
       "4     38.0                  3.0        1400.0            2.0      1.0   \n",
       "...    ...                  ...           ...            ...      ...   \n",
       "9995  44.0                  3.0        1850.0            2.0      1.0   \n",
       "9996  45.0                  3.0        2450.0            2.0      1.0   \n",
       "9997  44.0                  2.0        1250.0            1.0      1.0   \n",
       "9998  51.0                  5.0        1000.0            2.0      1.0   \n",
       "9999  43.0                  0.0        1500.0            1.0      1.0   \n",
       "\n",
       "      chemistry  biology  english  geography  history  mean_exam_points  \n",
       "0           0.0      0.0      0.0        0.0      0.0              90.0  \n",
       "1           1.0      0.0      0.0        0.0      0.0              71.0  \n",
       "2           0.0      0.0      0.0        0.0      0.0              45.0  \n",
       "3           0.0      0.0      0.0        0.0      0.0              92.0  \n",
       "4           0.0      0.0      0.0        0.0      0.0              58.0  \n",
       "...         ...      ...      ...        ...      ...               ...  \n",
       "9995        1.0      0.0      0.0        0.0      0.0              68.0  \n",
       "9996        1.0      0.0      1.0        0.0      0.0              72.0  \n",
       "9997        1.0      0.0      0.0        0.0      0.0              63.0  \n",
       "9998        0.0      1.0      0.0        0.0      0.0              64.0  \n",
       "9999        1.0      1.0      0.0        0.0      0.0              41.0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(X_new.to_numpy(), models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-114-3014a95b4f05>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ID['choose']=y_pred\n"
     ]
    }
   ],
   "source": [
    "ID['choose']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID.to_csv('predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
